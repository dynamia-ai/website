---
title: "Dynamia AI Raises Tens of Millions in Angel Round: Rooted in Open Source, Driving Heterogeneous Compute Efficiency"
slug: "dynamia-angel-funding"
date: "2026-01-05"
excerpt: "Shanghai Dynamia Intelligence Technology Co., Ltd. ('Dynamia AI'), an AI startup focused on heterogeneous compute scheduling and virtualization, recently completed tens of millions of RMB in angel financing, led by Fosun RCC with strong participation from Zhuopu Investment, seed investors, and industrial partners."
author: "Dynamia"
tags: ["financing", "angel round", "Fosun RCC", "Zhuopu Investment", "HAMi"]
language: "en"
coverImage: "/images/blog/dynamia-angel-funding/dynamia-angel-funding-announcement.jpg"
---

Shanghai Dynamia Intelligence Technology Co., Ltd. ("Dynamia AI"), an AI startup focused on heterogeneous compute scheduling and virtualization, **recently completed tens of millions of RMB in angel financing**. This round was **led by Fosun RCC**, with **strong participation from Zhuopu Investment, seed investors, and industrial partners**. Since receiving over 5 million RMB in seed financing last March, Dynamia AI has rapidly completed 2 rounds of financing in less than a year, demonstrating strong development momentum, with its technical prospects and commercial value gaining wide market recognition.

## Dynamia AI: Making Heterogeneous Compute Usable Through Open Source

Dynamia AI is always committed to **building the world's leading open-source heterogeneous compute scheduling solution, driving the compute efficiency revolution in the AI era through technology**. The company **initiated and leads the CNCF project HAMi**, which is currently the **only open-source project in the industry focused on heterogeneous GPU resource virtualization and efficient scheduling**. Through flexible, reliable, on-demand, and elastic GPU virtualization, it improves resource utilization and can be deployed in a plug-and-play, lightweight, and non-intrusive manner in any public cloud, private cloud, or hybrid cloud environment. In terms of ecosystem compatibility, HAMi fully supports NVIDIA, Ascend, Maxxiri, Cambricon, Hygon, Moore Threads, Iluvatar, Kunlunxin，燧原，and AWS, as well as other domestic and international mainstream GPU chips. At the same time, it seamlessly supports upstream and downstream mainstream open-source projects such as vLLM, Volcano, Koordinator, and Kueue, gradually forming a stable heterogeneous compute ecosystem.

Currently, HAMi has gathered **more than 360 contributors from 16 countries**, with continuous improvement in community activity. **Final users already exceed 200 enterprises**, covering domestic mainstream cloud vendors, internet companies, and KA users, and have expanded to overseas regions such as Southeast Asia and Europe, with extensive industry influence. In 2025, the "Efficiency Over Compute Power" series of Meetups initiated by Dynamia AI also received significant attention.

In just one year of commercial development, **Dynamia AI has received commercial orders from multiple leading customers, and the channel partnership system has rapidly expanded**, gradually gaining wide market recognition. Based on existing ecosystem development and extensive user feedback, Dynamia AI will further promote HAMi to achieve compatibility adaptation with more GPU vendors, continuously mine high-value scenario requirements, promote its ecological adaptation on the large model inference side, and build a compute service system with upstream and downstream collaboration. At the same time, it will launch core products 面向 enterprise market based on HAMi, continuously empowering customer production-grade scenarios.

![Team Photo](/images/blog/dynamia-angel-funding/dynamia-founding-team.jpg)

Dynamia AI's founding team members all come from **representative vendors in the AI infrastructure field such as 'DaoCloud', 4Paradigm, and Baidu**, as well as **domestic universities such as Tsinghua University and Zhejiang University**, with rich technical accumulation and industry experience in cloud computing, cloud-native, and GPU sharing and scheduling technologies. **Founder Zhang Xiao and co-founder Li Mengxuan are the authors of HAMi**, and other team members are also core contributors and maintainers of HAMi, possessing extensive technical influence and industry foresight.

## What Investors Say: From Open Source to Industry, They Empower Heterogeneous Compute Through Innovation

**Ye Lijuan, Executive Investment Director at Fosun RCC**, stated that heterogeneity will be the long-term pattern of the compute market. Whether GPU or new compute chips, it is the most important foundation of AI. Dynamia AI indispensably connects the compute end and application end in the AI big ecosystem, greatly improving compute efficiency for customers and saving expensive compute costs. The open-source HAMi has established a considerable-scale developer and user ecosystem—this path is also highly consistent with the open-source and collaborative development trend of the AI industry. The flexible, elastic, on-demand, and reliable virtualization technology provided by HAMi can achieve efficient segmentation and scheduling of computing power, significantly improving compute utilization, thereby bringing highly competitive return on investment (ROI) to global customers.

**Chen Minjie, Director at Zhuopu Investment**, mentioned in communication with Dynamia AI that in the previous generation of cloud computing era centered on CPU, virtualization giants like VMware emerged. Now in the AI intelligent computing era centered on GPU, there is also a huge mismatch between the compute demand of AI task loads and the underlying hardware allocation method. Virtualization is the core key to AI democratization. The current situation of diverse and heterogeneous domestic computing power also gives HAMi open source a deeper meaning. Open source is no longer just a feeling, but a necessity for survival and development, and a reshaping of the current computing order. HAMi wants to break the hardware barriers, make computing power a public infrastructure as readily available as water, and help diverse heterogeneous chips resonate with the global ecosystem. In this trend, HAMi is expected to become the global universal standard for heterogeneous compute scheduling virtualization.

**Chen Qiyan, Founder and CEO of incubating shareholder 'DaoCloud'**, stated that HAMi has formed a key ecological niche in AI infrastructure. 'DaoCloud' expects Dynamia AI to build its capabilities into a unified, general-purpose heterogeneous GPU management and virtualization standard. As AI technology converges to the open-source community, Dynamia AI has the potential to become a leader in this field, and both product systems have been deeply integrated with the HAMi enterprise version, achieving collaborative empowerment.

## Continuing Deep Cultivation of Open Source, Accelerating Enterprise Product Layout

**Zhang Xiao, Founder and CEO of Dynamia AI**, expressed heartfelt thanks to all new and old investors for their trust and support. He mentioned that since its inception, Dynamia AI has **taken open source as its technical gene, focusing on the core track of heterogeneous compute**. In the past year, relying on this key ecological positioning and continuous deep cultivation in the open-source community, Dynamia AI has made solid progress in technical precipitation and product iteration, **which is inseparable from the efforts of the team and also benefits from the continuous empowerment of investors in strategy and resources**.

This round of financing will mainly be used in three aspects of company development. **First, deepening open-source ecosystem construction**, the company will continue to implement the open-source strategy and maintain leading investment in this path. **Second, accelerating team construction and global layout**, focusing on expanding core technology R&D and ecological marketing teams, and building a sound channel system (if partners want to join Dynamia AI's global channel system, welcome to contact us). **Third, enterprise product R&D**, Dynamia AI will launch enterprise core products around enterprise-level capabilities such as elastic scaling, task priority scheduling, video memory over-allocation, and full-link observability, further promoting enterprise empowerment and commercial realization of open-source projects.

From technical innovation to ecological co-construction, from open-source community to global customers, Dynamia AI's rich open-source genes and innovation have demonstrated amazing growth speed in just one year, confirming its foresight in driving computing change through open source. In the future, as inference demand continues to deepen and application scenarios continue to expand, Dynamia AI will continue to improve computing efficiency for enterprises, injecting core power on the road to AGI.
