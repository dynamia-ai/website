---
title: DaoCloud：用 HAMi 构建更灵活的 GPU 云平台
date: '2026-01-13'
excerpt: >-
  在 AI 训练与推理需求持续增长的背景下，DaoCloud 在其公有与私有 GPU 云平台中使用 CNCF Sandbox 开源项目
  HAMi，构建了一套更加灵活、云原生的 GPU 资源管理方式。
author: Dynamia
tags:
  - DaoCloud
  - HAMi
  - 案例
  - GPU 云平台
  - vGPU
category: Customer Success Story
language: zh
coverImage: /images/blog/daocloud-hami-gpu-platform/daocloud-product-lines.png
---

在 AI 训练与推理需求持续增长的背景下，如何提升 GPU 利用率、降低算力成本，并同时兼顾多样化业务场景，成为云平台面临的核心挑战。

「DaoCloud 道客」围绕这一问题，在其公有与私有 GPU 云平台中使用 CNCF Sandbox 开源项目 HAMi，构建了一套更加灵活、云原生的 GPU 资源管理方式。本文基于 DaoCloud 在真实生产环境中的实践经验，梳理其在 GPU 云平台建设过程中引入 HAMi 的整体思路、落地过程与实际成效。

## 公司与产品背景：公有云与私有云并行的 GPU 平台

DaoCloud 面向不同类型用户，运营着两条核心产品线，并且均承载着大量 AI 训练与推理工作负载。

![DaoCloud 产品线](/images/blog/daocloud-hami-gpu-platform/daocloud-product-lines.png)

**算力云（d.run）** 是 DaoCloud 面向个人开发者与小微企业的公有 GPU 云服务。用户可按需购买 GPU 算力，用于 AI 训练和推理。为了满足自助购买与快速交付的需求，算力云采用相对轻量化的权限模型，并通过统一的 SKU 体系对外提供算力资源。

**DaoCloud Enterprise（DCE）** 则是一套面向企业客户的私有云容器平台。企业在自有环境中采购并部署 GPU 资源后，需要一个统一的平台来管理和分配这些算力。DCE 基于标准化的 Kubernetes 平台构建，支持多租户隔离、部门与队列级配额管理，并结合角色权限体系，为企业内部的 AI 训练与推理提供统一的算力资源池和算法开发平台。

## 工程背景：GPU 利用率与管理复杂度的双重挑战

在引入 HAMi 之前，DaoCloud 在 GPU 云平台的实际运行中面临着一系列共性问题。

在算力云场景下，GPU 主要以整卡方式分配，推理类和轻量任务往往只使用 GPU 的部分算力和显存，导致整体资源利用率偏低，同时也限制了 GPU SKU 的灵活设计。

在企业私有云（DCE）场景中，GPU 资源需要在多个部门、项目和队列之间共享，如何在保证隔离与配额约束的前提下，实现统一调度和高效使用，对平台提出了更高要求。

此外，随着平台逐步引入不同型号的 NVIDIA GPU 以及国产 GPU，加速器类型日趋多样，异构硬件的统一管理和调度复杂度也不断提升。

## 为什么选择 HAMi：云原生、厂商无关的 GPU 抽象层

在建设 GPU 训练平台时，DaoCloud 从**最终用户真正关心的问题**出发：

- 训练任务是否稳定、性能是否可预测

- 换 GPU、换集群是否需要改代码

- 出现性能问题时，平台能否给出清晰解释

围绕这些诉求，平台需要一套**对上屏蔽硬件差异、对下保持足够透明度**的 GPU 抽象层。

**HAMi 提供了一种不依赖厂商授权的 GPU 抽象方式**，使同一套训练任务能够在 NVIDIA 与国产 GPU 环境中保持一致的使用体验，避免用户被底层硬件与授权模型绑定，从而显著降低迁移和扩容成本。

同时，HAMi 的云原生设计使 GPU 能够像 CPU、内存一样融入 Kubernetes 调度体系。

对用户而言，这意味着：

- 无需理解 GPU 虚拟化细节

- 训练行为在不同规模与节点上更加一致

- 平台升级不会破坏既有训练流程

## 解决方案：HAMi 在 DaoCloud 平台中的实际落地

在算力云（d.run）中，DaoCloud 将 HAMi 集成到每个区域的 Kubernetes 集群中，实现 GPU 的 vGPU 切分与受控超卖。物理 GPU 被划分为不同规格的 vGPU 资源，并通过统一的 SKU 体系对外提供，用户可以根据实际需求选择合适的算力规格，而不必为整卡 GPU 付费。

在 DaoCloud Enterprise（DCE）中，HAMi 作为统一的 GPU 抽象层，将企业内部零散的 GPU 资源整合为共享算力池。vGPU 资源与平台原有的配额体系和 RBAC 权限模型深度集成，实现部门与队列级别的 GPU 配额控制，同时对算法工程师屏蔽底层硬件差异，简化使用体验。

在实际落地过程中，DaoCloud 将真实生产环境中暴露的 GPU 超卖、调度边界与异构硬件适配问题持续反馈至社区，并通过代码与实践验证，推动 HAMi 在相关能力上的持续演进。

## 数据与量化成效：更高利用率与更低成本

目前，d.run 已在国内及香港部署 **7 个活跃区域**，覆盖 **10+ 数据中心**。

在引入 HAMi 之后，通过 vGPU 切分与受控超卖机制，GPU 资源的使用效率得到显著提升。结合算力云（d.run）和企业私有云（DCE）的整体实践经验：

- **GPU 平均利用率提升至 80% 以上**；

- **GPU 相关的综合运营成本降低约 20%–30%**；

- HAMi 的模块化与云原生架构 **显著缩短了新区域和新集群的交付周期**，GPU SKU 的定义和上线流程更加标准化。

在不同区域规模和负载结构下，具体提升幅度存在一定差异。从工程运行视角来看，在多数生产场景中，平台能够实现 **70%–80% 以上的稳定 GPU 利用率水平**，并随着推理类与轻量任务占比提升，成本优化效果进一步显现。

## 近期动态

在最近的 HAMi Meetup 上海站，DaoCloud 产品负责人 **卢传佳** 分享到：

> "在 SaaS GPU 云场景下，最大的挑战并不只是'把 GPU 用起来'，而是如何在高波动、高并发的情况下，把单卡的价值持续释放出来。HAMi 提供的 vGPU 切片、算力配比和调度能力，让我们可以真正以云原生的方式对 GPU 进行池化和精细化运营。
>
> 对 d.run 来说，HAMi 不只是一个调度组件，而是算力云能够规模化运营的基础能力之一。它让我们在保障 SLA 的同时，实现了更高的资源复用率，也为平台在多区域、多硬件类型上的扩展提供了足够的灵活性。"
