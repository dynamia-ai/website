---
title: "【密瓜智能 | 用户案例】某头部智驾公司通过 HAMi 实现 GPU 精细化管理与资源利用最大化"
coverTitle: " 用户案例 | 智驾企业的 GPU 精细化管理"
slug: "A leading autonomous-driving company"
date: "2025-08-09"
excerpt: "某头部智驾公司在核心模型训练场景中，采用多机分布式训练，使用如 Ray、Volcano 等调度框架。"
author: "密瓜智能"
tags: ["KubeCon", "HAMi", "GPU 共享", "云原生", "Kubernetes", "AI 基础设施"]
coverImage: "/images/blog/A-leading-autonomous-driving-company/cover.jpg"
language: "zh"
---

>作为一个活跃的开源项目，HAMi 由来自 15+ 国家、350+ 贡献者共同维护，已被 200+ 企业与机构在实际生产环境中采纳，具备良好的可扩展性与支持保障。

## 用户简介

某头部智驾公司在核心模型训练场景中，采用多机分布式训练，使用如 Ray、Volcano 等调度框架。与此同时，也面向内部研发、测试、产品等团队提供云桌面环境，支持便捷的远程办公与模型开发。

在云桌面集群中，每位用户都可以创建一台带有图形界面的虚拟工作机，用于在任意地点进行模型编译、离线播包，或运行轻量的 PyTorch 实验。该场景对资源的敏感性更高，GPU 卡数量有限，因此 GPU 资源的调度与利用率成为平台稳定运行的关键因素。

## 项目挑战

由于云桌面集群的显卡数量相对有限，传统方案如 NVIDIA Time Slicing、vGPU、或 [KubeVirt](https://mp.weixin.qq.com/s/wTXTWD2Ts5U6YJcwWkkOzw) 的 GPU 直通方式，在资源调度灵活性和成本上，或多或少存在一些局限：

• **MIG 模式颗粒度有限**：MIG（Multi-Instance GPU）虽然支持资源切分，但仅适用于特定高端型号，切分形态固定，灵活性不足，难以满足多样化的业务需求；

• **云厂商方案兼容性弱**：如阿里云 CGPU、腾讯云 QGPU 等基于内核态的虚拟化方案，对操作系统内核版本有严格要求，限制了环境的自由度；在多云或混合云环境下也难以统一部署与管理，降低了整体平台的灵活性与可迁移性；

• **TimeSlicing 调度粗糙**：NVIDIA 原生的 Timeslicing 虽然能用，但资源隔离不满足要求，性能和稳定性没有保障，无法满足精细化的算力需求；

• **直通模式资源浪费**：全部采用 KubeVirt 等 GPU 直通方案时，GPU 以整卡粒度分配给虚拟机，难以细粒度利用，轻负载场景下易造成资源闲置，整体效率低下。

这些限制使得该公司在 GPU 集群管理上难以兼顾灵活性和成本效益，亟需一种更高效的解决方案。

## 解决方案

![1](/images/blog/A-leading-autonomous-driving-company/p1.jpg)

面对 GPU 资源调度的复杂需求，该公司创新性地采用了 **HAMi + KubeVirt** 混合架构，在云桌面平台中实现了灵活高效的 GPU 管理。该方案的核心设计在于：

**HAMi：容器级 GPU 虚拟化，提升资源利用率**
HAMi 负责容器环境的 GPU 调度，支持按需分配 vGPU 资源，用户通过远程桌面登录时，体验与本地计算机无异。通过单卡 3 倍虚拟化配置，GPU 资源利用率得到显著提升，有效缓解算力紧张问题。

**KubeVirt：直通模式保障高规格计算需求**
对于需要完整 GPU 算力或更强隔离性的训练任务，KubeVirt 提供 GPU 直通能力，确保虚拟机独占物理显卡，满足高性能计算需求。

用户可自由选择容器桌面或 GPU 直通虚拟机，两种模式共享同一 GPU 集群。平台将节点划分为 HAMi 和 KubeVirt 管理两类资源池，根据任务需求动态分配，最大化利用每一块 GPU 的算力。

## 为什么选择HAMi?

在众多 GPU 虚拟化方案中，HAMi 最终成为该头部智驾公司的技术选择，主要基于以下关键考量：

![2](/images/blog/A-leading-autonomous-driving-company/p2.png)

1. **精准匹配业务场景**

云桌面场景主要依赖容器隔离，无需复杂的批处理协同调度，HAMi 的轻量化设计恰好满足需求，后续也可结合 Volcano 实现更丰富的玩法。

2. **vCUDA 技术成熟稳定**

采用经过业界验证的 vCUDA 虚拟化技术，HAMi 运行至今，内部仅偶发宿主机资源竞争导致的调度失败，稳定性远超预期。

3. **显著降低 [TCO](https://baike.weixin.qq.com/v7082701.htm?scene_id=132&sid=9701872681904243761&ch=s1s)（总体拥有成本）**

相比其他方案，HAMi 无高端硬件限制、不增加额外内核维护成本；对比自研方案，又大幅减少了开发和维护投入。

4. **云原生友好架构**

基于 Kubernetes 原生调度扩展与设备插件体系，研发团队可快速上手，后续扩展和维护相对友好，而且还有密瓜智能核心团队与 HAMi 社区能够给予及时且有力的支持。

5. **面向未来的异构兼容性**

不仅支持 NVIDIA 显卡，还对国产 GPU 提供兼容支持，为后续算力基础设施的多元化布局预留空间。

## 成效与收益

通过引入 **HAMi** 并构建 **双轨 GPU 管理架构**，该公司在云桌面场景中实现了从资源紧张到高效调度的转变，具体成效包括：

![3](/images/blog/A-leading-autonomous-driving-company/p3.png)

- **GPU 利用率从大于 20% 提升至 60~70%，提升约 200%**：通过单卡虚拟化技术，有效消除资源闲置占用，让每块显卡发挥最大价值；

- **虚拟GPU资源池扩容 3 倍**：原本受限于物理卡数量的调度瓶颈被打破，研发团队随时可申请算力资源；

- **成本优化显著**：相比仅在部分高端卡上支持、切分形态固定且颗粒度受限的 MIG 模式，单卡虚拟化可在更多型号上实现灵活、细粒度的资源切分，充分释放存量硬件价值，避免因资源碎片化而额外采购显卡或扩容，整体降低 TCO。

***"以前 GPU 经常被几个虚拟机独占导致资源死锁，需要人工协调，现在通过 HAMi 实现单卡多容器共享后，同样卡数能撑起三倍桌面，研发同事随时都能获得所需算力资源。"—— 用户公司 AI 平台资深研发***

## 未来展望

随着业务规模扩大，该公司正将 HAMi 的应用从云桌面延伸至更多的场景，重点探索方向包括：

- **在模型训练集群中测试 HAMi 与 Ray、Volcano 等框架的集成效果**:
为提升训练任务的调度效率与资源利用率，平台正在评估将 HAMi 引入模型训练集群的可行性，探索其与现有的分布式计算框架和批量调度系统的协同机制，以解决资源碎片、调度排队等痛点问题。

- **支持异构加速设备的接入与统一调度**
随着加速芯片类型的日益多样，平台对异构资源统一管理的需求逐渐显现。HAMi 原生支持多类型计算设备的纳管与调度，未来将进一步扩展对异构加速卡的支持能力，构建灵活可扩展的异构算力管理平台，支撑多种 AI 任务场景。

## 结语

密瓜智能团队以及 HAMi 社区帮助此头部智驾公司在云桌面场景实现了从"资源争夺"到"按需分配"的进化，HAMi 自身的云原生基因也在该公司展现出向训练等核心场景延伸的潜力。在自动驾驶算法持续迭代的背景下，这种兼具效率和弹性的算力管理方式，正成为 AI 基础设施不可或缺的一环。

---

![5](/images/blog/PREP-EDU-HAMi/p5.png)

Dynamia 密瓜智能,  专注以 CNCF HAMi 项目为核心底座，提供 灵活、可靠、按需、弹性的 GPU 虚拟化 与异构算力调度、统一管理的全球化解决方案。可以插拔式、轻量化、无侵入地部署在任意公有云、私有云、混合云环境中，可支持 NVIDIA、昇腾、沐曦、寒武纪、海光、摩尔线程，天数智芯等异构芯片。

>官网：https://dynamia.ai

>邮箱：info@dynamia.ai






